{"pages":[{"title":"about","text":"整理一些日常思考，同时当工具导航网站用。 不定期更新。","link":"/about/index.html"},{"title":"links","text":"Here are some useful linksMath and PhysicsLinear AlgebraCalculusProgrammingGit CommandsConda CommandsMarkDownMusicChords诗歌平上去入表Other Blogs","link":"/links/index.html"}],"posts":[{"title":"Bitcoin Price Prediction Project","text":"使用机器学习技术，预测短期走势。比特币只是一个案例，理论上可以预测任何时间序列。准不准就是另外一回事了。 详细介绍等有空了再写。 代码： Datasource.py import requests import pandas as pd import time from datetime import datetime, timedelta import pytz import matplotlib.pyplot as plt BASE_URL = &quot;https://api.binance.com/api/v3/klines&quot; CET = pytz.timezone(&quot;Europe/Paris&quot;) # Central European Time def get_binance_ohlcv(symbol='BTCUSDT', interval='5m', limit=1000, start_time=None): &quot;&quot;&quot; Fetch OHLCV data from Binance starting at `start_time`. &quot;&quot;&quot; url = BASE_URL params = { 'symbol': symbol, 'interval': interval, 'limit': limit, } if start_time: params['startTime'] = start_time response = requests.get(url, params=params) data = response.json() if not isinstance(data, list): print(&quot;Error fetching:&quot;, data) return pd.DataFrame() df = pd.DataFrame(data, columns=[ 'timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_volume', 'taker_buy_quote_volume', 'ignore' ]) df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms') df.set_index('timestamp', inplace=True) df = df.astype({ 'open': 'float', 'high': 'float', 'low': 'float', 'close': 'float', 'volume': 'float' }) return df[['open', 'high', 'low', 'close', 'volume']] def fetch_full_history(symbol='BTCUSDT', interval='5m', save_every=50): &quot;&quot;&quot; Fetch all historical data since 2017 in chunks of 1000 rows. &quot;&quot;&quot; full_df = pd.DataFrame() start_time = int(datetime(2017, 7, 1).timestamp() * 1000) now = int(datetime.now().timestamp() * 1000) counter = 0 while start_time &lt; now: df = get_binance_ohlcv(symbol=symbol, interval=interval, start_time=start_time) if df.empty: break full_df = pd.concat([full_df, df]) start_time = int(df.index[-1].timestamp() * 1000) + 1 # next candle counter += 1 print(f&quot;Fetched window {counter}: {df.index[0]} to {df.index[-1]}, total rows: {len(full_df)}&quot;) # Optional: Save interim files if counter % save_every == 0: filename = f&quot;btc_5min_partial_{counter}.xlsx&quot; #full_df.to_excel(filename) print(f&quot;Saved partial data to {filename}&quot;) time.sleep(0.4) # throttle to avoid rate limiting return full_df if __name__ == &quot;__main__&quot;: #df = fetch_full_history() #df.to_excel(&quot;btc_5min_full.xlsx&quot;) df = &quot;btc_5min_full.xlsx&quot; df = pd.read_excel(df, index_col=0, parse_dates=True) print(&quot;Saved full dataset to btc_5min_full.xlsx&quot;) # Plot plt.figure(figsize=(14, 6)) df['close'].plot(title=&quot;BTC/USDT - 5 Minute Closing Price (Since 2017)&quot;, grid=True) plt.xlabel(&quot;Time (CET)&quot;) plt.ylabel(&quot;Price (USDT)&quot;) plt.tight_layout() plt.savefig(&quot;btc_price_full_plot.png&quot;) plt.show() 数据收集 Preprocess.py import pandas as pd import numpy as np from sklearn.preprocessing import MinMaxScaler from ta.momentum import RSIIndicator from ta.trend import MACD from ta.volatility import BollingerBands RAW_DATA_FILE = &quot;btc_5min_full.xlsx&quot; PROCESSED_DATA_FILE = &quot;btc_processed.pkl&quot; def load_and_prepare_data(file_path=RAW_DATA_FILE): df = pd.read_excel(file_path, index_col=0, parse_dates=True) # Ensure the index is sorted and cleaned df.sort_index(inplace=True) df = df[~df.index.duplicated(keep='first')] return df def preprocess_data(df, resample_interval=None): # Optional resample if resample_interval: df = df.resample(resample_interval).agg({ 'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum' }).dropna() # Handle missing values (forward fill) df.ffill(inplace=True) # Normalize price and volume scaler = MinMaxScaler() df[['open', 'high', 'low', 'close', 'volume']] = scaler.fit_transform(df[['open', 'high', 'low', 'close', 'volume']]) # Create lag features (1, 2, 3 steps back) for lag in [1, 2, 3]: df[f'close_lag_{lag}'] = df['close'].shift(lag) # Technical indicators df['rsi'] = RSIIndicator(close=df['close'], window=14).rsi() df['macd'] = MACD(close=df['close']).macd() bb = BollingerBands(close=df['close'], window=20, window_dev=2) df['bb_upper'] = bb.bollinger_hband() df['bb_lower'] = bb.bollinger_lband() # Drop rows with NaNs from indicator calculations df.dropna(inplace=True) return df, scaler def save_processed_data(df, path=PROCESSED_DATA_FILE): df.to_pickle(path) print(f&quot;✅ Preprocessed data saved to {path}&quot;) def main(): df_raw = load_and_prepare_data() df_processed, _ = preprocess_data(df_raw) save_processed_data(df_processed) if __name__ == &quot;__main__&quot;: main() print(&quot;✅ Preprocessing complete!&quot;) 数据预处理 Model.py import pandas as pd import numpy as np import xgboost as xgb from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score import matplotlib.pyplot as plt import joblib import os DATA_PATH = &quot;btc_processed.pkl&quot; MODEL_SAVE_PATH = &quot;xgb_model.pkl&quot; # Helper to add temporal features def add_time_features(df): df['hour'] = df.index.hour df['dayofweek'] = df.index.dayofweek return df # Add rolling features def add_rolling_features(df): df['rolling_std_12'] = df['close'].rolling(window=12).std() df['rolling_return_12'] = df['close'].pct_change(periods=12) return df def walk_forward_validation(df, window_size=10000, horizon=288): errors = [] predictions = [] actuals = [] timestamps = [] i = 0 while i + window_size + horizon &lt; len(df): train = df.iloc[i:i + window_size].copy() test = df.iloc[i + window_size:i + window_size + horizon].copy() X_train = train.drop(['close'], axis=1) y_train = train['close'] X_test = test.drop(['close'], axis=1) y_test = test['close'] # Remove any potential inf or NaN values X_train.replace([np.inf, -np.inf], np.nan, inplace=True) X_test.replace([np.inf, -np.inf], np.nan, inplace=True) X_train.dropna(inplace=True) X_test.dropna(inplace=True) y_train = y_train.loc[X_train.index] y_test = y_test.loc[X_test.index] model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=6, learning_rate=0.05) model.fit(X_train, y_train) # Save model and features joblib.dump(model, &quot;xgb_model.pkl&quot;) joblib.dump(X_train.columns.tolist(), &quot;feature_list.pkl&quot;) # 👈 Save feature list y_pred = model.predict(X_test) predictions.extend(y_pred) actuals.extend(y_test) timestamps.extend(X_test.index) rmse = np.sqrt(mean_squared_error(y_test, y_pred)) mae = mean_absolute_error(y_test, y_pred) r2 = r2_score(y_test, y_pred) errors.append((rmse, mae, r2)) print(f&quot;Window {i // horizon}: RMSE={rmse:.6f}, MAE={mae:.6f}, R2={r2:.6f}&quot;) i += horizon return predictions, actuals, timestamps, errors, model def main(): df = pd.read_pickle(DATA_PATH) df = add_time_features(df) df = add_rolling_features(df) df.replace([np.inf, -np.inf], np.nan, inplace=True) df.dropna(inplace=True) y = df['close'].copy() X = df.drop(columns=['close']) df_full = df.copy() preds, actuals, times, errors, final_model = walk_forward_validation(df_full) # Save final model joblib.dump(final_model, MODEL_SAVE_PATH) print(f&quot;\\nModel saved to {MODEL_SAVE_PATH}&quot;) # Convert to series pred_series = pd.Series(preds, index=times) actual_series = pd.Series(actuals, index=times) # Plot plt.figure(figsize=(14, 6)) plt.plot(actual_series, label=&quot;Actual&quot;) plt.plot(pred_series, label=&quot;Predicted&quot;) plt.title(&quot;Predicted vs Actual BTC Price (Walk-forward)&quot;) plt.legend() plt.grid() plt.tight_layout() plt.savefig(&quot;btc_pred_vs_actual.png&quot;) plt.show() # Metrics summary errors = np.array(errors) print(f&quot;\\nAverage RMSE: {errors[:, 0].mean():.6f}&quot;) print(f&quot;Average MAE: {errors[:, 1].mean():.6f}&quot;) print(f&quot;Average R2: {errors[:, 2].mean():.6f}&quot;) if __name__ == &quot;__main__&quot;: main() 模型训练 Prediction.py import pandas as pd import numpy as np import joblib import matplotlib.pyplot as plt from sklearn.preprocessing import MinMaxScaler from model import add_time_features, add_rolling_features from ta.momentum import RSIIndicator from ta.trend import MACD from ta.volatility import BollingerBands DATA_PATH = &quot;btc_processed.pkl&quot; MODEL_PATH = &quot;xgb_model.pkl&quot; FEATURES_PATH = &quot;feature_list.pkl&quot; SCALER_PATH = &quot;btc_scaler.pkl&quot; # Optional if you saved it separately FUTURE_STEPS = 1000 # number of future steps to forecast (e.g., 12 x 5min = 1 hour) INTERVAL_MINUTES = 5 print(&quot;🔄 Loading model and data...&quot;) # Load data and model df = pd.read_pickle(DATA_PATH) model = joblib.load(MODEL_PATH) feature_list = joblib.load(FEATURES_PATH) # Extract last known values for forecasting df_live = df.copy() scaler = MinMaxScaler() df_live[['open', 'high', 'low', 'close', 'volume']] = scaler.fit_transform(df_live[['open', 'high', 'low', 'close', 'volume']]) print(f&quot;🔮 Predicting {FUTURE_STEPS} steps into the future...&quot;) future_preds = [] future_times = [] for step in range(FUTURE_STEPS): print(f&quot;🔍 Step {step}: df_live shape = {df_live.shape}&quot;) # Create one row of future timestamp last_timestamp = df_live.index[-1] next_timestamp = last_timestamp + pd.Timedelta(minutes=INTERVAL_MINUTES) new_row = df_live.iloc[-1].copy() new_row.name = next_timestamp df_live = pd.concat([df_live, pd.DataFrame([new_row])]) # Apply feature engineering df_extended = df_live.copy() df_extended = add_time_features(df_extended) df_extended = add_rolling_features(df_extended) df_extended['rsi'] = RSIIndicator(close=df_extended['close'], window=14).rsi() df_extended['macd'] = MACD(close=df_extended['close']).macd() bb = BollingerBands(close=df_extended['close'], window=20, window_dev=2) df_extended['bb_upper'] = bb.bollinger_hband() df_extended['bb_lower'] = bb.bollinger_lband() df_extended.replace([np.inf, -np.inf], np.nan, inplace=True) df_extended.dropna(inplace=True) if df_extended.empty: print(f&quot;⚠️ Step {step}: No data after feature engineering. Stopping forecast.&quot;) break X_latest = df_extended[feature_list].iloc[[-1]] y_pred = model.predict(X_latest)[0] future_preds.append(y_pred) future_times.append(next_timestamp) # Update 'close' in df_live with the prediction for next iteration df_live.loc[next_timestamp, 'close'] = y_pred # Convert predictions back to original scale (denormalize) # Use inverse_transform on 'close' column only close_min = scaler.data_min_[3] # 'close' is the 4th column (index 3) close_max = scaler.data_max_[3] denorm_preds = [pred * (close_max - close_min) + close_min for pred in future_preds] pred_series = pd.Series(denorm_preds, index=pd.DatetimeIndex(future_times)) print(&quot;\\n✅ Forecast complete. Here are the next predicted values:&quot;) print(pred_series) # Plot results plt.figure(figsize=(12, 5)) pred_series.plot(label=&quot;Predicted Close&quot;, color='orange') plt.title(&quot;Future BTC Price Forecast&quot;) plt.xlabel(&quot;Time&quot;) plt.ylabel(&quot;Price (USDT)&quot;) plt.grid() plt.legend() plt.tight_layout() plt.savefig(&quot;btc_future_forecast.png&quot;) plt.show() 预测","link":"/2025/06/16/Bitcoin-Price-Prediction-Project/"},{"title":"F-Voice Evolution Simulation","text":"我们都知道男性在青春期之后声音会变低沉（频率变低），但是成年女性与小孩的声音都是高频，可是两者之间是否有明显区别？这个项目将通过模拟试图回答这个问题。 code: 生成音频 from gtts import gTTS from pydub import AudioSegment from pydub.playback import play import os import numpy as np # 设置输出目录 output_dir = &quot;female_voice_evolution&quot; os.makedirs(output_dir, exist_ok=True) # 年龄范围（10 到 32 岁，每隔2岁） ages = list(range(10, 34, 2)) # 中文句子模板 template = &quot;你好，我叫小李。今年{}岁，很高兴认识你。&quot; # 音调和速度的模拟函数（通过年龄映射） def change_pitch_and_speed(sound, age): # 模拟音调变化（10岁高音，32岁低音） # 以12岁为基准，音调每年降低0.5%，速度每年降低0.3% pitch_shift = 1.2 - ((age - 10) * 0.015) # 比如：10岁是1.2倍频率，32岁是0.84倍 speed_change = 1.1 - ((age - 10) * 0.01) # 比如：10岁语速快，32岁慢一些 # 改变速度 sound = sound._spawn(sound.raw_data, overrides={ &quot;frame_rate&quot;: int(sound.frame_rate * speed_change) }).set_frame_rate(sound.frame_rate) # 改变音调（改变采样率模拟pitch） sound = sound._spawn(sound.raw_data, overrides={ &quot;frame_rate&quot;: int(sound.frame_rate * pitch_shift) }).set_frame_rate(22050) return sound # 生成并保存每个年龄的音频样本 for age in ages: text = template.format(age) tts = gTTS(text=text, lang='zh-cn') temp_path = os.path.join(output_dir, f&quot;temp_{age}.mp3&quot;) tts.save(temp_path) # 加载音频 sound = AudioSegment.from_file(temp_path) # 模拟音调/语速变化 processed = change_pitch_and_speed(sound, age) # 输出文件 final_path = os.path.join(output_dir, f&quot;xiaoli_{age}years_old.mp3&quot;) processed.export(final_path, format=&quot;mp3&quot;) print(f&quot;生成：{final_path}&quot;) # 删除中间文件 os.remove(temp_path) 合成音轨 from pydub import AudioSegment import os # 输入目录（你之前保存的音频） input_dir = &quot;female_voice_evolution&quot; output_file = &quot;xiao_li_voice_evolution_combined.mp3&quot; # 获取所有音频文件，按年龄顺序排序 audio_files = sorted([ f for f in os.listdir(input_dir) if f.endswith(&quot;.mp3&quot;) and f.startswith(&quot;xiaoli_&quot;) ], key=lambda x: int(x.split(&quot;_&quot;)[1].replace(&quot;years&quot;, &quot;&quot;).replace(&quot;old.mp3&quot;, &quot;&quot;))) # 创建一个空音轨 combined = AudioSegment.empty() # 1 秒静音间隔 silence = AudioSegment.silent(duration=1000) # 依次拼接所有音频文件 for file in audio_files: path = os.path.join(input_dir, file) audio = AudioSegment.from_file(path) combined += audio + silence # 导出最终合成音轨 combined.export(output_file, format=&quot;mp3&quot;) print(f&quot;合成音轨已保存为：{output_file}&quot;)","link":"/2025/06/16/F-Voice-Evolution-Simulation/"},{"title":"city night","text":"文化研究实践课程考察夜游(图片有点多，想看可以先挂着) 出发啦，10：00，校门口 地铁，迎面走来的快乐的人 一个人的城市 玉兰花香 德基下班员工 反射 某大厦 鸟瞰南京 无限城 最安静的酒吧，没人说话 DJ小姐姐 再次回到马路上，凌晨 路上奇怪的小区 南京最大的酒吧 入口是星星走廊和硕大的蔷薇 酒吧边吓人的游乐场，奇怪的空间叙事 不夜城（其实两点就赶人啦） 她们坐在这里，不太开心 镜头晃得妙 酒吐的少年 三点返校","link":"/2023/05/03/city-night/"},{"title":"诗词创作","text":"一种即兴的老派文学样式 五言绝句平起首押归寺 风霞曲粉香，洞竹续江梁。月刹悲词岁，归衣畏雨长。 仄起首押悲怪 日瀑涝风钟，西台曙怪笼。昏医灾四海，水起尔饥冬。 平起首不押仲秋 烟阳凉米市，苦雨爱迟枝。木雪还沙鹄，游舟采仲秋。 仄起首不押 五言律诗七言绝句平起首押田园即兴 春苔豆扇羡田桥，醉至山间戏女萧。可入眠泉怀北调，村巾飞曲唤青苗。 仄起首押夜入寒山 雪落空山劝客迟，轻吟酒暖骗佳诗。遥遥冰月平天举，烛里飞蛾伴吾痴。 七言律诗 七言律詩正格： 1、平起首句入韻式（平起，指第一個音節是平聲；首句入韻，指第一句句末押韻。下同） 平平仄仄仄平平，（韻）仄仄平平仄仄平。韻仄仄平平平仄仄， 平平仄仄仄平平。韻平平仄仄平平仄， 仄仄平平仄仄平。韻仄仄平平平仄仄， 平平仄仄仄平平。韻 2、平起首句不入韻式： 平平仄仄平平仄， 仄仄平平仄仄平。韻仄仄平平平仄仄， 平平仄仄仄平平。韻平平仄仄平平仄， 仄仄平平仄仄平。韻仄仄平平平仄仄， 平平仄仄仄平平。韻 3、仄起首句入韻式： 仄仄平平仄仄平，（韻）平平仄仄仄平平。韻平平仄仄平平仄， 仄仄平平仄仄平。韻仄仄平平平仄仄， 平平仄仄仄平平。韻平平仄仄平平仄， 仄仄平平仄仄平。韻 4、仄起首句不入韻式： 仄仄平平平仄仄， 平平仄仄仄平平。韻平平仄仄平平仄， 仄仄平平仄仄平。韻仄仄平平平仄仄， 平平仄仄仄平平。韻平平仄仄平平仄， 仄仄平平仄仄平。韻 五言律詩正格： 1、仄起首句入韻式（仄起，指第一個音節是仄聲；首句入韻，指第一句句末押韻。下同） 仄仄仄平平，（韻） 平平仄仄平。韻平平平仄仄，仄仄仄平平。韻仄仄平平仄，平平仄仄平。韻平平平仄仄，仄仄仄平平。韻 2、仄起首句不入韻式： 仄仄平平仄， 平平仄仄平。韻平平平仄仄， 仄仄仄平平。韻仄仄平平仄， 平平仄仄平。韻平平平仄仄， 仄仄仄平平。韻 3、平起首句入韻式： 平平仄仄平，（韻） 仄仄仄平平。韻仄仄平平仄，平平仄仄平。韻平平平仄仄，仄仄仄平平。韻仄仄平平仄，平平仄仄平。韻 4、平起首句不入韻式： 平平平仄仄，仄仄仄平平。韻仄仄平平仄，平平仄仄平。韻平平平仄仄，仄仄仄平平。韻仄仄平平仄，平平仄仄平。韻 五言绝句，平起式，正格： 平平仄仄平（韵）仄仄仄平平（韵）仄仄平平仄平平仄仄平（韵） 五言绝句，仄起式，正格： 仄仄仄平平（韵）平平仄仄平（韵）平平平仄仄仄仄仄平平（韵） 五言绝句，仄起式，偏格： 仄仄平平仄平平仄仄平（韵）平平平仄仄仄仄仄平平（韵） 五言绝句，平起式，偏格： 平平平仄仄仄仄仄平平（韵）仄仄平平仄平平仄仄平（韵） 七言绝句，仄起式，正格： 仄仄平平仄仄平（韵）平平仄仄仄平平（韵）平平仄仄平平仄仄仄平平仄仄平（韵） 七言绝句，平起式，正格： 平平仄仄仄平平（韵）仄仄平平仄仄平（韵）仄仄平平平仄仄平平仄仄仄平平（韵） 七言绝句，仄起式，偏格： 仄仄平平平仄仄平平仄仄仄平平（韵）平平仄仄平平仄仄仄平平仄仄平（韵） 七言绝句，平起式，偏格： 平平仄仄平平仄仄仄平平仄仄平（韵）仄仄平平平仄仄平平仄仄仄平平（韵）","link":"/2025/06/16/poetry/"},{"title":"RGB true-color satellite cloud image","text":"Satellite meteorology course homework, teaching you how to draw a satellite cloud image from scratch.卫星气象课程小作业，教你零基础画卫星云图。 卫星气象课程小作业原来随便注册一个账号，就可以画卫星图了。。。下面是一些指导，你需要：1.网站账号，并完善相关信息2.matlab3.就这么多介绍性的不感兴趣就直接跳过吧 Satellite Meteorology Course AssignmentIt used to be that you could register an account and easily draw satellite images…Here are some instructions that you need: 1.Website account and complete relevant information2.Matlab3.That’s itIf you’re not interested in the introduction, just skip it. English versionHow to download data:sign in and follow the link: https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/6/MOD021KM Data Introduction:The MODIS Level-1B dataset contains radiance values of 36 discrete spectral bands ranging from 0.4 to 14.4 micrometers, which have been calibrated and geolocated. Channels 1 and 2 have a resolution of 250 meters, channels 3 to 7 have a resolution of 500 meters, and the rest have a resolution of 1 kilometer. It should be noted that the radiance data and associated uncertainties of the 250 and 500-meter bands have been aggregated to a 1-kilometer resolution. A single MODIS 1B data file contains one scene established by 203 scans, sampled 1354 times in the cross-track direction, equivalent to approximately 5 minutes of data. The scene is composed of 1354 by 2030 pixels and covers a spatial range of 2330 kilometers by 2030 kilometers. MOD021KM and MYD021KM are the datasets for the Terra and Aqua satellites, respectively.Analyzing the link above, it is not difficult to find that it points to the data of the Terra satellite, and users can choose the time according to their needs. The data selected in the Matlab code below is MOD021KM.A2019173.0125.061.2019176162129.hdf. Basic Principle:True-color composite refers to the composite color processing of multispectral remote sensing images. If the wavelengths of the three bands involved in the composite are the same or similar to the wavelengths of the corresponding red, green, and blue primaries, the color of the composite image will approximate the true color of the ground objects. Basic Method:Read the reflectance data of 0.46mm, 0.55mm, and 0.64mm of 1km resolution in the MODIS Level-1B dataset.Combine them as red, green, and blue primaries respectively (R = 0.64mm reflectance, G = 0.55mm reflectance, and B = 0.46mm reflectance).Use the three-dimensional vector obtained from step 2) to draw an RGB true-color image. 中文版本如何得到数据:注册一个账号，并进入以下网址: https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/6/MOD021KM 数据简介MODIS Level-1B数据集包含位于0.4微米至14.4微米光谱区域的36个离散波段的辐射值，并进行了校准和地理定位。其中，通道1和2的分辨率为250米，通道3至7的分辨率为500米，其余为1公里的分辨率。值得注意的是，250米和500米波段的辐射度数据及其相关的不确定性已经汇总到1公里分辨率。一个单一的MODIS 1B级数据文件将包含一个由203次扫描建立的场景，在交叉轨道方向上采样1354次，相当于大约5分钟的数据。场景将由1354乘以2030像素组成，空间覆盖范围为2330公里乘2030公里。MOD021KM、MYD021KM分别是Terra卫星和Aqua卫星的数据集。分析上面的链接不难发现其指向的是Terra卫星的数据，大家可以根据需求选着时间。在下面的matlab代码中选择的数据是&gt;MOD021KM.A2019173.0125.061.2019176162129.hdf 基本原理真彩色合成是指多光谱遥感图像彩色合成处理时，如果参与合成的三个波段的波长与对应的红、绿、蓝三种原色的波长相同或近似，那么合成图像的颜色就会近似于地面景物的真实颜色的一种合成。 基本方法1）读取MODIS Level-1B数据集中，1km分辨率的0.46mm、0.55mm、0.64mm的反射率数据；2）分别用0.64mm、0.55mm、0.46mm作为红绿蓝三原色进行组合（R = 0.64mm reflectance, G = 0.55mm reflectance, and B = 0.46mm reflectance）；3）利用2）组合成的三维向量绘制RGB真彩色图像。 相关代码matlab:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061filename='MOD021KM.A2019173.0125.061.2019176162129.hdf';datdinfo=hdfinfo(filename);EV_250_Aggr1km_RefSB = hdfread(filename, 'EV_250_Aggr1km_RefSB');EV_500_Aggr1km_RefSB = hdfread(filename, 'EV_500_Aggr1km_RefSB');EV_1KM_Emissive = hdfread(filename, 'EV_1KM_Emissive');ref_064=EV_250_Aggr1km_RefSB(1,:,:);ref_064=squeeze(ref_064);ref_064=double(ref_064);info250mv = {datdinfo.Vgroup.Vgroup(2).SDS(5).Attributes.Value};reflectance_scales_250m = double(cell2mat(info250mv(9)));reflectance_offsets_250m = double(cell2mat(info250mv(10)));ref_064=reflectance_scales_250m(1)*(ref_064-reflectance_offsets_250m(1));ref_046=EV_500_Aggr1km_RefSB(1,:,:);ref_046=squeeze(ref_046);ref_046=double(ref_046);info500mv = {datdinfo.Vgroup.Vgroup(2).SDS(8).Attributes.Value};reflectance_scales_500m = double(cell2mat(info500mv(9)));reflectance_offsets_500m = double(cell2mat(info500mv(10)));ref_046=reflectance_scales_500m(1)*(ref_046-reflectance_offsets_500m(1));ref_055=EV_500_Aggr1km_RefSB(2,:,:);ref_055=squeeze(ref_055);ref_055=double(ref_055);ref_055=reflectance_scales_500m(2)*(ref_055-reflectance_offsets_500m(2));lat = hdfread(filename,'Latitude');lon = hdfread(filename,'Longitude');[row, col]= size(ref_055);lon1 = imresize(lon,[row, col]);lat1 = imresize(lat,[row, col]);lon1=double(lon1);lat1=double(lat1);latmin=min(min(lat1));lonmin=min(min(lon1));latmax=max(max(lat1));lonmax=max(max(lon1));ref_064(ref_064&gt;1)=1;ref_064(ref_064&lt;0)=0;ref_064=ref_064.^(0.4);ref_055(ref_055&gt;1)=1;ref_055(ref_055&lt;0)=0;ref_055=ref_055.^(0.4);ref_046(ref_046&gt;1)=1;ref_046(ref_046&lt;0)=0;ref_046=ref_046.^(0.4);rgb_modis(:,:,1)=ref_064; %Redrgb_modis(:,:,2)=ref_055; %greenrgb_modis(:,:,3)=ref_046; %bluehsv_modis=rgb2hsv(rgb_modis);hsv_modis(:,:,2)=hsv_modis(:,:,2)*2;rgb_modis=hsv2rgb(hsv_modis);figureh=axesm ('Frame','on','MapProjection','eqdcylin','FLineWidth',3, 'Grid',... 'on','GColor','k','GLineWidth',1, 'GLineStyle', '--',... 'PLineLocation',5,'MLineLocation',5,'ParallelLabel','on',... 'PLabelLocation', 10,'MLabelLocation', 10,'MeridianLabel','on',... 'MapLatLimit',[latmin latmax],'MapLonLimit',[lonmin lonmax],... 'FontName','Times New Roman','FontSize',12,... 'FontWeight','normal','LabelUnits','degrees');geoshow(lat, lon, rgb_modis);box offset(gca,'Visible','off')print(gcf,'-r300','-dpng',['MOD021KM.A2019173.0125_truecolorRGB.png']); Explanation of CodeHere are some commands that may be useful: To read detailed information of the hdf file: hdfinfoTo read data from hdf file: hdfreadTo convert array to double precision: doubleTo resize an array: imresizeTo draw an image with a map projection: axesm + geoshow For specific function usage, please refer to the help documentation of Matlab. Here are some commands for enhancing the image: When using 0.64mm, 0.55mm, and 0.46mm as the red, green, and blue primary colors for combination, the data for each channel can be adjusted as follows:Limit the data range between 0 and 1;Use the following formula for adjustment: data = data^a (a ~ 0.4); Before drawing the image, use the rgb2hsv function to convert the combined RGB array to the HSV array. After enhancing the saturation, use the hsv2rgb function to convert back to the RGB array (enhancement coefficient b ~ 2).The values of a and b are not fixed and can be experimented with within a reasonable range. 代码相关说明一些可能需要的命令：读取hdf文件的详细信息： hdfinfo读取hdf文件中的数据： hdfread将数组转换为双精度： double调整数组大小： imresize绘制地图投影的图像： axesm + geoshow具体的函数使用，参考matlab的help文档 一些用于美化图像的命令：1）在利用0.64mm、0.55mm、0.46mm作为红绿蓝三原色进行组合时，对每一个通道的数据可以进行如下修正：限定数据范围上下限为0和1；可用如下公式进行修正：data = data^a(a~0.4）；2）绘图前，利用rgb2hsv函数将组合成的RGB数组转化为HSV数组，增强饱和度之后，再利用hsv2rgb函数转化回RGB数组（增强系数b ~2）。a，b没有固定值，可以在合理范围内尝试。","link":"/2023/05/03/satellite/"}],"tags":[{"name":"thoughts","slug":"thoughts","link":"/tags/thoughts/"},{"name":"strange_life","slug":"strange-life","link":"/tags/strange-life/"},{"name":"literature","slug":"literature","link":"/tags/literature/"},{"name":"as","slug":"as","link":"/tags/as/"}],"categories":[]}