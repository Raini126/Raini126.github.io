<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Raini"><title>Raini126</title><meta name="description" content="A simple and beautiful blog"><meta name="keywords" content="Blog,åšå®¢,Hexo"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.webp"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/insight.css"><link rel="stylesheet" href="/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 5.4.2"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li> <a class="current" href="/">Home</a></li><li> <a href="/archives">Archives</a></li><li> <a href="/tags">Tags</a></li><li> <a href="/about">About</a></li><li> <a href="/links">Links</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)" style="display:none;"> </a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/images/logo.webp"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/images/logo@2x.webp" style="width:220px;" alt="favicon"><h3 title=""><a href="/">Raini126</a></h3><div class="description"><p>A simple and beautiful blog</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/Raini126"><i class="fa fa-github"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> å…¨ç«™CC-BY-SA-3.0 </span><i class="fa fa-star"></i><span> Raini</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2025/06/16/poetry/">è¯—è¯åˆ›ä½œ</a></h3></div><div class="post-content"><div class="card"><p><h1 id="è¯—è¯åˆ›ä½œ"><a href="#è¯—è¯åˆ›ä½œ" class="headerlink" title="è¯—è¯åˆ›ä½œ"></a>è¯—è¯åˆ›ä½œ</h1></p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2025-06-16</span><i class="fa fa-tag"></i><a class="tag" href="/tags/literature/" title="literature">literature </a><span class="leancloud_visitors"></span><span>About 1186 words, 3 min 57 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2025/06/16/F-Voice-Evolution-Simulation/">F-Voice Evolution Simulation</a></h3></div><div class="post-content"><div class="card"><p><p>æˆ‘ä»¬éƒ½çŸ¥é“ç”·æ€§åœ¨é’æ˜¥æœŸä¹‹åå£°éŸ³ä¼šå˜ä½æ²‰ï¼ˆé¢‘ç‡å˜ä½ï¼‰ï¼Œä½†æ˜¯æˆå¹´å¥³æ€§ä¸å°å­©çš„å£°éŸ³éƒ½æ˜¯é«˜é¢‘ï¼Œå¯æ˜¯ä¸¤è€…ä¹‹é—´æ˜¯å¦æœ‰æ˜æ˜¾åŒºåˆ«ï¼Ÿè¿™ä¸ªé¡¹ç›®å°†é€šè¿‡æ¨¡æ‹Ÿè¯•å›¾å›ç­”è¿™ä¸ªé—®é¢˜ã€‚</p>
<p>code:</p>
<details>
<summary>ç”ŸæˆéŸ³é¢‘</summary>
    
<pre><code>    from gtts import gTTS
    from pydub import AudioSegment
    from pydub.playback import play
    import os
    import numpy as np

    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = &quot;female_voice_evolution&quot;
    os.makedirs(output_dir, exist_ok=True)

    # å¹´é¾„èŒƒå›´ï¼ˆ10 åˆ° 32 å²ï¼Œæ¯éš”2å²ï¼‰
    ages = list(range(10, 34, 2))

    # ä¸­æ–‡å¥å­æ¨¡æ¿
    template = &quot;ä½ å¥½ï¼Œæˆ‘å«å°æã€‚ä»Šå¹´&#123;&#125;å²ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚&quot;

    # éŸ³è°ƒå’Œé€Ÿåº¦çš„æ¨¡æ‹Ÿå‡½æ•°ï¼ˆé€šè¿‡å¹´é¾„æ˜ å°„ï¼‰
    def change_pitch_and_speed(sound, age):
        # æ¨¡æ‹ŸéŸ³è°ƒå˜åŒ–ï¼ˆ10å²é«˜éŸ³ï¼Œ32å²ä½éŸ³ï¼‰
        # ä»¥12å²ä¸ºåŸºå‡†ï¼ŒéŸ³è°ƒæ¯å¹´é™ä½0.5%ï¼Œé€Ÿåº¦æ¯å¹´é™ä½0.3%
        pitch_shift = 1.2 - ((age - 10) * 0.015)  # æ¯”å¦‚ï¼š10å²æ˜¯1.2å€é¢‘ç‡ï¼Œ32å²æ˜¯0.84å€
        speed_change = 1.1 - ((age - 10) * 0.01)  # æ¯”å¦‚ï¼š10å²è¯­é€Ÿå¿«ï¼Œ32å²æ…¢ä¸€äº›

        # æ”¹å˜é€Ÿåº¦
        sound = sound._spawn(sound.raw_data, overrides=&#123;
            &quot;frame_rate&quot;: int(sound.frame_rate * speed_change)
        &#125;).set_frame_rate(sound.frame_rate)

        # æ”¹å˜éŸ³è°ƒï¼ˆæ”¹å˜é‡‡æ ·ç‡æ¨¡æ‹Ÿpitchï¼‰
        sound = sound._spawn(sound.raw_data, overrides=&#123;
            &quot;frame_rate&quot;: int(sound.frame_rate * pitch_shift)
        &#125;).set_frame_rate(22050)

        return sound

    # ç”Ÿæˆå¹¶ä¿å­˜æ¯ä¸ªå¹´é¾„çš„éŸ³é¢‘æ ·æœ¬
    for age in ages:
        text = template.format(age)
        tts = gTTS(text=text, lang=&#39;zh-cn&#39;)
        temp_path = os.path.join(output_dir, f&quot;temp_&#123;age&#125;.mp3&quot;)
        tts.save(temp_path)

        # åŠ è½½éŸ³é¢‘
        sound = AudioSegment.from_file(temp_path)

        # æ¨¡æ‹ŸéŸ³è°ƒ/è¯­é€Ÿå˜åŒ–
        processed = change_pitch_and_speed(sound, age)

        # è¾“å‡ºæ–‡ä»¶
        final_path = os.path.join(output_dir, f&quot;xiaoli_&#123;age&#125;years_old.mp3&quot;)
        processed.export(final_path, format=&quot;mp3&quot;)
        print(f&quot;ç”Ÿæˆï¼š&#123;final_path&#125;&quot;)

        # åˆ é™¤ä¸­é—´æ–‡ä»¶
        os.remove(temp_path)
</code></pre>
</details>

<details>
<summary>åˆæˆéŸ³è½¨</summary>
    
<pre><code>from pydub import AudioSegment
import os

# è¾“å…¥ç›®å½•ï¼ˆä½ ä¹‹å‰ä¿å­˜çš„éŸ³é¢‘ï¼‰
input_dir = &quot;female_voice_evolution&quot;
output_file = &quot;xiao_li_voice_evolution_combined.mp3&quot;

# è·å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ï¼ŒæŒ‰å¹´é¾„é¡ºåºæ’åº
audio_files = sorted([
    f for f in os.listdir(input_dir) if f.endswith(&quot;.mp3&quot;) and f.startswith(&quot;xiaoli_&quot;)
], key=lambda x: int(x.split(&quot;_&quot;)[1].replace(&quot;years&quot;, &quot;&quot;).replace(&quot;old.mp3&quot;, &quot;&quot;)))

# åˆ›å»ºä¸€ä¸ªç©ºéŸ³è½¨
combined = AudioSegment.empty()

# 1 ç§’é™éŸ³é—´éš”
silence = AudioSegment.silent(duration=1000)

# ä¾æ¬¡æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
for file in audio_files:
    path = os.path.join(input_dir, file)
    audio = AudioSegment.from_file(path)
    combined += audio + silence

# å¯¼å‡ºæœ€ç»ˆåˆæˆéŸ³è½¨
combined.export(output_file, format=&quot;mp3&quot;)
print(f&quot;åˆæˆéŸ³è½¨å·²ä¿å­˜ä¸ºï¼š&#123;output_file&#125;&quot;)
</code></pre>
</details></p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2025-06-16</span><i class="fa fa-tag"></i><a class="tag" href="/tags/thoughts/" title="thoughts">thoughts </a><span class="leancloud_visitors"></span><span>About 612 words, 2 min 2 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2025/06/16/Bitcoin-Price-Prediction-Project/">Bitcoin Price Prediction Project</a></h3></div><div class="post-content"><div class="card"><p><span id="more"></span>
<p>ä½¿ç”¨æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œé¢„æµ‹çŸ­æœŸèµ°åŠ¿ã€‚æ¯”ç‰¹å¸åªæ˜¯ä¸€ä¸ªæ¡ˆä¾‹ï¼Œç†è®ºä¸Šå¯ä»¥é¢„æµ‹ä»»ä½•æ—¶é—´åºåˆ—ã€‚å‡†ä¸å‡†å°±æ˜¯å¦å¤–ä¸€å›äº‹äº†ã€‚</p>
<p>è¯¦ç»†ä»‹ç»ç­‰æœ‰ç©ºäº†å†å†™ã€‚</p>
<p>ä»£ç ï¼š</p>
<details>
<summary>Datasource.py</summary>

<pre><code>import requests
import pandas as pd
import time
from datetime import datetime, timedelta
import pytz
import matplotlib.pyplot as plt
BASE_URL = &quot;https://api.binance.com/api/v3/klines&quot;
CET = pytz.timezone(&quot;Europe/Paris&quot;)  # Central European Time

def get_binance_ohlcv(symbol=&#39;BTCUSDT&#39;, interval=&#39;5m&#39;, limit=1000, start_time=None):
    &quot;&quot;&quot;
    Fetch OHLCV data from Binance starting at `start_time`.
    &quot;&quot;&quot;
    url = BASE_URL
    params = &#123;
        &#39;symbol&#39;: symbol,
        &#39;interval&#39;: interval,
        &#39;limit&#39;: limit,
    &#125;
    if start_time:
        params[&#39;startTime&#39;] = start_time
    response = requests.get(url, params=params)
    data = response.json()
    if not isinstance(data, list):
        print(&quot;Error fetching:&quot;, data)
        return pd.DataFrame()
    df = pd.DataFrame(data, columns=[
        &#39;timestamp&#39;, &#39;open&#39;, &#39;high&#39;, &#39;low&#39;, &#39;close&#39;, &#39;volume&#39;,
        &#39;close_time&#39;, &#39;quote_asset_volume&#39;, &#39;number_of_trades&#39;,
        &#39;taker_buy_base_volume&#39;, &#39;taker_buy_quote_volume&#39;, &#39;ignore&#39;
    ])
    df[&#39;timestamp&#39;] = pd.to_datetime(df[&#39;timestamp&#39;], unit=&#39;ms&#39;)
    df.set_index(&#39;timestamp&#39;, inplace=True)
    df = df.astype(&#123;
        &#39;open&#39;: &#39;float&#39;,
        &#39;high&#39;: &#39;float&#39;,
        &#39;low&#39;: &#39;float&#39;,
        &#39;close&#39;: &#39;float&#39;,
        &#39;volume&#39;: &#39;float&#39;
    &#125;)
    return df[[&#39;open&#39;, &#39;high&#39;, &#39;low&#39;, &#39;close&#39;, &#39;volume&#39;]]

def fetch_full_history(symbol=&#39;BTCUSDT&#39;, interval=&#39;5m&#39;, save_every=50):
    &quot;&quot;&quot;
    Fetch all historical data since 2017 in chunks of 1000 rows.
    &quot;&quot;&quot;
    full_df = pd.DataFrame()
    start_time = int(datetime(2017, 7, 1).timestamp() * 1000)
    now = int(datetime.now().timestamp() * 1000)
    counter = 0
    while start_time &lt; now:
        df = get_binance_ohlcv(symbol=symbol, interval=interval, start_time=start_time)
        if df.empty:
            break
        full_df = pd.concat([full_df, df])
        start_time = int(df.index[-1].timestamp() * 1000) + 1  # next candle
        counter += 1
        print(f&quot;Fetched window &#123;counter&#125;: &#123;df.index[0]&#125; to &#123;df.index[-1]&#125;, total rows: &#123;len(full_df)&#125;&quot;)
        # Optional: Save interim files
        if counter % save_every == 0:
            filename = f&quot;btc_5min_partial_&#123;counter&#125;.xlsx&quot;
            #full_df.to_excel(filename)
            print(f&quot;Saved partial data to &#123;filename&#125;&quot;)
        time.sleep(0.4)  # throttle to avoid rate limiting
    return full_df
if __name__ == &quot;__main__&quot;:
    #df = fetch_full_history()
    #df.to_excel(&quot;btc_5min_full.xlsx&quot;)
    df = &quot;btc_5min_full.xlsx&quot;
    df = pd.read_excel(df, index_col=0, parse_dates=True)
    print(&quot;Saved full dataset to btc_5min_full.xlsx&quot;)
    # Plot
    plt.figure(figsize=(14, 6))
    df[&#39;close&#39;].plot(title=&quot;BTC/USDT - 5 Minute Closing Price (Since 2017)&quot;, grid=True)
    plt.xlabel(&quot;Time (CET)&quot;)
    plt.ylabel(&quot;Price (USDT)&quot;)
    plt.tight_layout()
    plt.savefig(&quot;btc_price_full_plot.png&quot;)
    plt.show()
</code></pre>
</details>
æ•°æ®æ”¶é›†
<details>
<summary>Preprocess.py</summary>

<pre><code>import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from ta.momentum import RSIIndicator
from ta.trend import MACD
from ta.volatility import BollingerBands

RAW_DATA_FILE = &quot;btc_5min_full.xlsx&quot;
PROCESSED_DATA_FILE = &quot;btc_processed.pkl&quot;

def load_and_prepare_data(file_path=RAW_DATA_FILE):
    df = pd.read_excel(file_path, index_col=0, parse_dates=True)

    # Ensure the index is sorted and cleaned
    df.sort_index(inplace=True)
    df = df[~df.index.duplicated(keep=&#39;first&#39;)]

    return df

def preprocess_data(df, resample_interval=None):
    # Optional resample
    if resample_interval:
        df = df.resample(resample_interval).agg(&#123;
            &#39;open&#39;: &#39;first&#39;,
            &#39;high&#39;: &#39;max&#39;,
            &#39;low&#39;: &#39;min&#39;,
            &#39;close&#39;: &#39;last&#39;,
            &#39;volume&#39;: &#39;sum&#39;
        &#125;).dropna()

    # Handle missing values (forward fill)
    df.ffill(inplace=True)

    # Normalize price and volume
    scaler = MinMaxScaler()
    df[[&#39;open&#39;, &#39;high&#39;, &#39;low&#39;, &#39;close&#39;, &#39;volume&#39;]] = scaler.fit_transform(df[[&#39;open&#39;, &#39;high&#39;, &#39;low&#39;, &#39;close&#39;, &#39;volume&#39;]])

    # Create lag features (1, 2, 3 steps back)
    for lag in [1, 2, 3]:
        df[f&#39;close_lag_&#123;lag&#125;&#39;] = df[&#39;close&#39;].shift(lag)

    # Technical indicators
    df[&#39;rsi&#39;] = RSIIndicator(close=df[&#39;close&#39;], window=14).rsi()
    df[&#39;macd&#39;] = MACD(close=df[&#39;close&#39;]).macd()
    bb = BollingerBands(close=df[&#39;close&#39;], window=20, window_dev=2)
    df[&#39;bb_upper&#39;] = bb.bollinger_hband()
    df[&#39;bb_lower&#39;] = bb.bollinger_lband()

    # Drop rows with NaNs from indicator calculations
    df.dropna(inplace=True)

    return df, scaler

def save_processed_data(df, path=PROCESSED_DATA_FILE):
    df.to_pickle(path)
    print(f&quot;âœ… Preprocessed data saved to &#123;path&#125;&quot;)

def main():
    df_raw = load_and_prepare_data()
    df_processed, _ = preprocess_data(df_raw)
    save_processed_data(df_processed)

if __name__ == &quot;__main__&quot;:
    main()
    print(&quot;âœ… Preprocessing complete!&quot;)
</code></pre>
</details>
æ•°æ®é¢„å¤„ç†
<details>
<summary>Model.py</summary>
    import pandas as pd
    import numpy as np
    import xgboost as xgb
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    import matplotlib.pyplot as plt
    import joblib
    import os

<pre><code>DATA_PATH = &quot;btc_processed.pkl&quot;
MODEL_SAVE_PATH = &quot;xgb_model.pkl&quot;

# Helper to add temporal features
def add_time_features(df):
    df[&#39;hour&#39;] = df.index.hour
    df[&#39;dayofweek&#39;] = df.index.dayofweek
    return df

# Add rolling features
def add_rolling_features(df):
    df[&#39;rolling_std_12&#39;] = df[&#39;close&#39;].rolling(window=12).std()
    df[&#39;rolling_return_12&#39;] = df[&#39;close&#39;].pct_change(periods=12)
    return df

def walk_forward_validation(df, window_size=10000, horizon=288):
    errors = []
    predictions = []
    actuals = []
    timestamps = []

    i = 0
    while i + window_size + horizon &lt; len(df):
        train = df.iloc[i:i + window_size].copy()
        test = df.iloc[i + window_size:i + window_size + horizon].copy()

        X_train = train.drop([&#39;close&#39;], axis=1)
        y_train = train[&#39;close&#39;]

        X_test = test.drop([&#39;close&#39;], axis=1)
        y_test = test[&#39;close&#39;]

        # Remove any potential inf or NaN values
        X_train.replace([np.inf, -np.inf], np.nan, inplace=True)
        X_test.replace([np.inf, -np.inf], np.nan, inplace=True)
        X_train.dropna(inplace=True)
        X_test.dropna(inplace=True)
        y_train = y_train.loc[X_train.index]
        y_test = y_test.loc[X_test.index]

        model = xgb.XGBRegressor(objective=&#39;reg:squarederror&#39;, n_estimators=100, max_depth=6, learning_rate=0.05)
        model.fit(X_train, y_train)

        # Save model and features
        joblib.dump(model, &quot;xgb_model.pkl&quot;)
        joblib.dump(X_train.columns.tolist(), &quot;feature_list.pkl&quot;)  # ğŸ‘ˆ Save feature list

        y_pred = model.predict(X_test)

        predictions.extend(y_pred)
        actuals.extend(y_test)
        timestamps.extend(X_test.index)

        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        errors.append((rmse, mae, r2))

        print(f&quot;Window &#123;i // horizon&#125;: RMSE=&#123;rmse:.6f&#125;, MAE=&#123;mae:.6f&#125;, R2=&#123;r2:.6f&#125;&quot;)

        i += horizon

    return predictions, actuals, timestamps, errors, model

def main():
    df = pd.read_pickle(DATA_PATH)

    df = add_time_features(df)
    df = add_rolling_features(df)
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(inplace=True)

    y = df[&#39;close&#39;].copy()
    X = df.drop(columns=[&#39;close&#39;])
    df_full = df.copy()

    preds, actuals, times, errors, final_model = walk_forward_validation(df_full)

    # Save final model
    joblib.dump(final_model, MODEL_SAVE_PATH)
    print(f&quot;\nModel saved to &#123;MODEL_SAVE_PATH&#125;&quot;)

    # Convert to series
    pred_series = pd.Series(preds, index=times)
    actual_series = pd.Series(actuals, index=times)

    # Plot
    plt.figure(figsize=(14, 6))
    plt.plot(actual_series, label=&quot;Actual&quot;)
    plt.plot(pred_series, label=&quot;Predicted&quot;)
    plt.title(&quot;Predicted vs Actual BTC Price (Walk-forward)&quot;)
    plt.legend()
    plt.grid()
    plt.tight_layout()
    plt.savefig(&quot;btc_pred_vs_actual.png&quot;)
    plt.show()

    # Metrics summary
    errors = np.array(errors)
    print(f&quot;\nAverage RMSE: &#123;errors[:, 0].mean():.6f&#125;&quot;)
    print(f&quot;Average MAE: &#123;errors[:, 1].mean():.6f&#125;&quot;)
    print(f&quot;Average R2:  &#123;errors[:, 2].mean():.6f&#125;&quot;)

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
</details>
æ¨¡å‹è®­ç»ƒ
<details>
<summary>Prediction.py</summary>
    import pandas as pd
    import numpy as np
    import joblib
    import matplotlib.pyplot as plt
    from sklearn.preprocessing import MinMaxScaler
    from model import add_time_features, add_rolling_features
    from ta.momentum import RSIIndicator
    from ta.trend import MACD
    from ta.volatility import BollingerBands

<pre><code>DATA_PATH = &quot;btc_processed.pkl&quot;
MODEL_PATH = &quot;xgb_model.pkl&quot;
FEATURES_PATH = &quot;feature_list.pkl&quot;
SCALER_PATH = &quot;btc_scaler.pkl&quot;  # Optional if you saved it separately

FUTURE_STEPS = 1000  # number of future steps to forecast (e.g., 12 x 5min = 1 hour)
INTERVAL_MINUTES = 5

print(&quot;ğŸ”„ Loading model and data...&quot;)

# Load data and model
df = pd.read_pickle(DATA_PATH)
model = joblib.load(MODEL_PATH)
feature_list = joblib.load(FEATURES_PATH)

# Extract last known values for forecasting
df_live = df.copy()
scaler = MinMaxScaler()
df_live[[&#39;open&#39;, &#39;high&#39;, &#39;low&#39;, &#39;close&#39;, &#39;volume&#39;]] = scaler.fit_transform(df_live[[&#39;open&#39;, &#39;high&#39;, &#39;low&#39;, &#39;close&#39;, &#39;volume&#39;]])

print(f&quot;ğŸ”® Predicting &#123;FUTURE_STEPS&#125; steps into the future...&quot;)

future_preds = []
future_times = []

for step in range(FUTURE_STEPS):
    print(f&quot;ğŸ” Step &#123;step&#125;: df_live shape = &#123;df_live.shape&#125;&quot;)

    # Create one row of future timestamp
    last_timestamp = df_live.index[-1]
    next_timestamp = last_timestamp + pd.Timedelta(minutes=INTERVAL_MINUTES)

    new_row = df_live.iloc[-1].copy()
    new_row.name = next_timestamp
    df_live = pd.concat([df_live, pd.DataFrame([new_row])])

    # Apply feature engineering
    df_extended = df_live.copy()
    df_extended = add_time_features(df_extended)
    df_extended = add_rolling_features(df_extended)

    df_extended[&#39;rsi&#39;] = RSIIndicator(close=df_extended[&#39;close&#39;], window=14).rsi()
    df_extended[&#39;macd&#39;] = MACD(close=df_extended[&#39;close&#39;]).macd()
    bb = BollingerBands(close=df_extended[&#39;close&#39;], window=20, window_dev=2)
    df_extended[&#39;bb_upper&#39;] = bb.bollinger_hband()
    df_extended[&#39;bb_lower&#39;] = bb.bollinger_lband()

    df_extended.replace([np.inf, -np.inf], np.nan, inplace=True)
    df_extended.dropna(inplace=True)

    if df_extended.empty:
        print(f&quot;âš ï¸ Step &#123;step&#125;: No data after feature engineering. Stopping forecast.&quot;)
        break

    X_latest = df_extended[feature_list].iloc[[-1]]
    y_pred = model.predict(X_latest)[0]
    future_preds.append(y_pred)
    future_times.append(next_timestamp)

    # Update &#39;close&#39; in df_live with the prediction for next iteration
    df_live.loc[next_timestamp, &#39;close&#39;] = y_pred

# Convert predictions back to original scale (denormalize)

# Use inverse_transform on &#39;close&#39; column only
close_min = scaler.data_min_[3]  # &#39;close&#39; is the 4th column (index 3)
close_max = scaler.data_max_[3]

denorm_preds = [pred * (close_max - close_min) + close_min for pred in future_preds]
pred_series = pd.Series(denorm_preds, index=pd.DatetimeIndex(future_times))

print(&quot;\nâœ… Forecast complete. Here are the next predicted values:&quot;)
print(pred_series)

# Plot results
plt.figure(figsize=(12, 5))
pred_series.plot(label=&quot;Predicted Close&quot;, color=&#39;orange&#39;)
plt.title(&quot;Future BTC Price Forecast&quot;)
plt.xlabel(&quot;Time&quot;)
plt.ylabel(&quot;Price (USDT)&quot;)
plt.grid()
plt.legend()
plt.tight_layout()
plt.savefig(&quot;btc_future_forecast.png&quot;)
plt.show()
</code></pre>
</details>
é¢„æµ‹</p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2025-06-16</span><i class="fa fa-tag"></i><a class="tag" href="/tags/thoughts/" title="thoughts">thoughts </a><span class="leancloud_visitors"></span><span>About 1758 words, 5 min 51 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2023/05/03/city-night/">city night</a></h3></div><div class="post-content"><div class="card"><p><h2 id="æ–‡åŒ–ç ”ç©¶å®è·µè¯¾ç¨‹è€ƒå¯Ÿå¤œæ¸¸-å›¾ç‰‡æœ‰ç‚¹å¤šï¼Œæƒ³çœ‹å¯ä»¥å…ˆæŒ‚ç€"><a href="#æ–‡åŒ–ç ”ç©¶å®è·µè¯¾ç¨‹è€ƒå¯Ÿå¤œæ¸¸-å›¾ç‰‡æœ‰ç‚¹å¤šï¼Œæƒ³çœ‹å¯ä»¥å…ˆæŒ‚ç€" class="headerlink" title="æ–‡åŒ–ç ”ç©¶å®è·µè¯¾ç¨‹è€ƒå¯Ÿå¤œæ¸¸(å›¾ç‰‡æœ‰ç‚¹å¤šï¼Œæƒ³çœ‹å¯ä»¥å…ˆæŒ‚ç€)"></a>æ–‡åŒ–ç ”ç©¶å®è·µè¯¾ç¨‹è€ƒå¯Ÿå¤œæ¸¸(å›¾ç‰‡æœ‰ç‚¹å¤šï¼Œæƒ³çœ‹å¯ä»¥å…ˆæŒ‚ç€)</h2></p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2023-05-03</span><i class="fa fa-tag"></i><a class="tag" href="/tags/strange-life/" title="strange_life">strange_life </a><span class="leancloud_visitors"></span><span>About 181 words, 36 sec  read</span></div></div></div></div><div class="post animated fadeInDown"><div class="post-title"><h3><a href="/2023/05/03/satellite/">RGB true-color satellite cloud image</a></h3></div><div class="post-content"><div class="card"><p><p>Satellite meteorology course homework, teaching you how to draw a satellite cloud image from scratch.<br>å«æ˜Ÿæ°”è±¡è¯¾ç¨‹å°ä½œä¸šï¼Œæ•™ä½ é›¶åŸºç¡€ç”»å«æ˜Ÿäº‘å›¾ã€‚</p></p></div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2023-05-03</span><i class="fa fa-tag"></i><a class="tag" href="/tags/as/" title="as">as </a><span class="leancloud_visitors"></span><span>About 1715 words, 5 min 43 sec  read</span></div></div></div></div><div class="pagination"><ul class="clearfix"></ul></div></div></div></div><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)",},CONTENT_URL:"/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="Search..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div></body></html>